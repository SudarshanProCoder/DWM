{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8f4b96",
   "metadata": {
    "papermill": {
     "duration": 0.003689,
     "end_time": "2025-03-18T08:02:48.774681",
     "exception": false,
     "start_time": "2025-03-18T08:02:48.770992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://devra.ai/analyst/notebook/1431/image.jpg\" style=\"width: 100%; height: auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dda4cd",
   "metadata": {
    "papermill": {
     "duration": 0.00271,
     "end_time": "2025-03-18T08:02:48.780714",
     "exception": false,
     "start_time": "2025-03-18T08:02:48.778004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:center; border-radius:15px; padding:15px; color:white; margin:0; font-family: 'Orbitron', sans-serif; background: #2E0249; background: #11001C; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.3); overflow:hidden; margin-bottom: 1em;\">  <div style=\"font-size:150%; color:#FEE100\"><b>Amazon Stock Data 2000-2025 Analysis</b></div>  <div>This notebook was created with the help of <a href=\"https://devra.ai/ref/kaggle\" style=\"color:#6666FF\">Devra AI</a></div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d53bc",
   "metadata": {
    "papermill": {
     "duration": 0.002642,
     "end_time": "2025-03-18T08:02:48.786368",
     "exception": false,
     "start_time": "2025-03-18T08:02:48.783726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction and Curiosity](#Introduction-and-Curiosity)\n",
    "- [Data Loading and Initial Exploration](#Data-Loading-and-Initial-Exploration)\n",
    "- [Data Cleaning and Preprocessing](#Data-Cleaning-and-Preprocessing)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Predictive Modeling: Predicting Closing Price](#Predictive-Modeling:-Predicting-Closing-Price)\n",
    "- [Conclusion and Future Directions](#Conclusion-and-Future-Directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be727cce",
   "metadata": {
    "papermill": {
     "duration": 0.00257,
     "end_time": "2025-03-18T08:02:48.791924",
     "exception": false,
     "start_time": "2025-03-18T08:02:48.789354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction and Curiosity\n",
    "\n",
    "Stock data spanning 25 years can reveal fascinating trends and unexpected twists in market dynamics. In this notebook, we explore the Amazon stock data from 2000 to 2025 with an inquisitive mind and a dry sense of humor. If you find these insights useful, please consider upvoting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9650b2b4",
   "metadata": {
    "papermill": {
     "duration": 3.142606,
     "end_time": "2025-03-18T08:02:51.937805",
     "exception": false,
     "start_time": "2025-03-18T08:02:48.795199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238c891",
   "metadata": {
    "papermill": {
     "duration": 0.003368,
     "end_time": "2025-03-18T08:02:51.944668",
     "exception": false,
     "start_time": "2025-03-18T08:02:51.941300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf92400e",
   "metadata": {
    "papermill": {
     "duration": 0.27452,
     "end_time": "2025-03-18T08:02:52.222483",
     "exception": false,
     "start_time": "2025-03-18T08:02:51.947963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (6321, 7)\n",
      "                        date      open      high       low     close  \\\n",
      "0  2000-01-03 00:00:00-05:00  4.075000  4.478125  3.952344  4.468750   \n",
      "1  2000-01-04 00:00:00-05:00  4.268750  4.575000  4.087500  4.096875   \n",
      "2  2000-01-05 00:00:00-05:00  3.525000  3.756250  3.400000  3.487500   \n",
      "3  2000-01-06 00:00:00-05:00  3.565625  3.634375  3.200000  3.278125   \n",
      "4  2000-01-07 00:00:00-05:00  3.350000  3.525000  3.309375  3.478125   \n",
      "\n",
      "   adj_close     volume  \n",
      "0   4.468750  322352000  \n",
      "1   4.096875  349748000  \n",
      "2   3.487500  769148000  \n",
      "3   3.278125  375040000  \n",
      "4   3.478125  210108000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6321 entries, 0 to 6320\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   date       6321 non-null   object \n",
      " 1   open       6321 non-null   float64\n",
      " 2   high       6321 non-null   float64\n",
      " 3   low        6321 non-null   float64\n",
      " 4   close      6321 non-null   float64\n",
      " 5   adj_close  6321 non-null   float64\n",
      " 6   volume     6321 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 345.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Amazon stock data 2000-2025.csv'\n",
    "df = pd.read_csv(file_path, parse_dates=['date'], encoding='ascii', delimiter=',')\n",
    "print('Data shape:', df.shape)\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635f919",
   "metadata": {
    "papermill": {
     "duration": 0.003016,
     "end_time": "2025-03-18T08:02:52.228748",
     "exception": false,
     "start_time": "2025-03-18T08:02:52.225732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bca0018",
   "metadata": {
    "papermill": {
     "duration": 0.066282,
     "end_time": "2025-03-18T08:02:52.298974",
     "exception": false,
     "start_time": "2025-03-18T08:02:52.232692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional date features created.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Day_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03 00:00:00-05:00</td>\n",
       "      <td>4.075000</td>\n",
       "      <td>4.478125</td>\n",
       "      <td>3.952344</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>322352000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04 00:00:00-05:00</td>\n",
       "      <td>4.268750</td>\n",
       "      <td>4.575000</td>\n",
       "      <td>4.087500</td>\n",
       "      <td>4.096875</td>\n",
       "      <td>4.096875</td>\n",
       "      <td>349748000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05 00:00:00-05:00</td>\n",
       "      <td>3.525000</td>\n",
       "      <td>3.756250</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.487500</td>\n",
       "      <td>3.487500</td>\n",
       "      <td>769148000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06 00:00:00-05:00</td>\n",
       "      <td>3.565625</td>\n",
       "      <td>3.634375</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.278125</td>\n",
       "      <td>3.278125</td>\n",
       "      <td>375040000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07 00:00:00-05:00</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>3.525000</td>\n",
       "      <td>3.309375</td>\n",
       "      <td>3.478125</td>\n",
       "      <td>3.478125</td>\n",
       "      <td>210108000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date      open      high       low     close  \\\n",
       "0 2000-01-03 00:00:00-05:00  4.075000  4.478125  3.952344  4.468750   \n",
       "1 2000-01-04 00:00:00-05:00  4.268750  4.575000  4.087500  4.096875   \n",
       "2 2000-01-05 00:00:00-05:00  3.525000  3.756250  3.400000  3.487500   \n",
       "3 2000-01-06 00:00:00-05:00  3.565625  3.634375  3.200000  3.278125   \n",
       "4 2000-01-07 00:00:00-05:00  3.350000  3.525000  3.309375  3.478125   \n",
       "\n",
       "   adj_close     volume  Year  Month  Day  DayOfWeek  Day_Number  \n",
       "0   4.468750  322352000  2000      1    3          0           0  \n",
       "1   4.096875  349748000  2000      1    4          1           1  \n",
       "2   3.487500  769148000  2000      1    5          2           2  \n",
       "3   3.278125  375040000  2000      1    6          3           3  \n",
       "4   3.478125  210108000  2000      1    7          4           4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In many cases, date columns imported as strings can lead to issues when using the .dt accessor.\n",
    "# Hence, it's important to validate that the 'date' column is of datetime type and convert it if necessary.\n",
    "\n",
    "if not pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Drop records with invalid dates, if any\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Create additional date features for granular analysis\n",
    "df['Year'] = df['date'].dt.year\n",
    "df['Month'] = df['date'].dt.month\n",
    "df['Day'] = df['date'].dt.day\n",
    "df['DayOfWeek'] = df['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# Create a numeric representation of the date: days since the earliest date\n",
    "df['Day_Number'] = (df['date'] - df['date'].min()).dt.days\n",
    "\n",
    "print('Additional date features created.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2bc72",
   "metadata": {
    "papermill": {
     "duration": 0.003149,
     "end_time": "2025-03-18T08:02:52.305841",
     "exception": false,
     "start_time": "2025-03-18T08:02:52.302692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f9ab264",
   "metadata": {
    "papermill": {
     "duration": 29.307042,
     "end_time": "2025-03-18T08:03:21.616279",
     "exception": false,
     "start_time": "2025-03-18T08:02:52.309237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's perform several visualizations to understand the data better\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# 1. Pair Plot of Numeric Variables\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "if numeric_df.shape[1] >= 2:\n",
    "    sns.pairplot(numeric_df)\n",
    "    plt.title('Pair Plot of Numeric Variables')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "# 2. Correlation Heatmap (only if there are 4 or more numeric columns)\n",
    "if numeric_df.shape[1] >= 4:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    corr = numeric_df.corr()\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Heatmap of Numeric Features')\n",
    "    \n",
    "\n",
    "# 3. Histogram of the 'close' prices\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df['close'], kde=True, bins=30, color='skyblue')\n",
    "plt.title('Distribution of Closing Prices')\n",
    "plt.xlabel('Closing Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "# 4. Box Plot for 'volume' to inspect outliers\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x=df['volume'], color='lightgreen')\n",
    "plt.title('Box Plot of Trading Volume')\n",
    "plt.xlabel('Volume')\n",
    "\n",
    "\n",
    "# 5. Count Plot for Day of Week to see if trading days vary\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x=df['DayOfWeek'], palette='pastel')\n",
    "plt.title('Count of Records by Day of Week')\n",
    "plt.xlabel('Day of Week (Monday=0)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "\n",
    "# 6. Grouped Bar Plot: Average Volume by Year\n",
    "avg_volume_by_year = df.groupby('Year')['volume'].mean().reset_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Year', y='volume', data=avg_volume_by_year, palette='viridis')\n",
    "plt.title('Average Trading Volume by Year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064ff042-24b6-4716-9151-f6558d682e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_volume_by_year = df.groupby('Year')['volume'].mean().reset_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Year', y='volume', data=avg_volume_by_year, palette='viridis')\n",
    "plt.title('Average Trading Volume by Year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675d666",
   "metadata": {
    "papermill": {
     "duration": 0.003736,
     "end_time": "2025-03-18T08:03:21.623820",
     "exception": false,
     "start_time": "2025-03-18T08:03:21.620084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predictive Modeling: Predicting Closing Price\n",
    "\n",
    "We now build a simple predictor to forecast the closing price based on historical data. While predicting stock prices is notoriously challenging (and sometimes frustratingly unpredictable), this model serves as a good instructional example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0dde40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T08:03:21.632681Z",
     "iopub.status.busy": "2025-03-18T08:03:21.632327Z",
     "iopub.status.idle": "2025-03-18T08:03:23.027876Z",
     "shell.execute_reply": "2025-03-18T08:03:23.026870Z"
    },
    "papermill": {
     "duration": 1.402241,
     "end_time": "2025-03-18T08:03:23.029825",
     "exception": false,
     "start_time": "2025-03-18T08:03:21.627584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R2 Score: 0.9999\n",
      "Mean Absolute Error: 0.2139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Define the feature set and target variable\n",
    "feature_cols = ['open', 'high', 'low', 'volume', 'Year', 'Month', 'Day', 'DayOfWeek', 'Day_Number']\n",
    "target = 'close'\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[feature_cols]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute accuracy metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Linear Regression R2 Score: {r2:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Permutation Importance to see feature relevance\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importance = result.importances_mean\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feature_cols, importance, color='slateblue')\n",
    "plt.title('Permutation Importance of Features')\n",
    "plt.xlabel('Mean Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Actual vs Predicted values\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='teal')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title('Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Actual Closing Price')\n",
    "plt.ylabel('Predicted Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a7e7a",
   "metadata": {
    "papermill": {
     "duration": 0.00338,
     "end_time": "2025-03-18T08:03:23.037070",
     "exception": false,
     "start_time": "2025-03-18T08:03:23.033690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion and Future Directions\n",
    "\n",
    "In this notebook, we walked through the complete data science workflow from data loading, cleaning, exploratory analysis to building a simple regression model for predicting closing prices. We leveraged a variety of visualizations—from heatmaps through pair plots to grouped bar charts—to uncover insights hidden in the long-term evolution of Amazon stock data.\n",
    "\n",
    "The predictor, while simplistic, provides a benchmark for more sophisticated future models. Future work could incorporate time series specific approaches (like ARIMA or LSTM networks) and include external economic or sentiment data for improved accuracy.\n",
    "\n",
    "If this notebook helped shed some light on the stock data trends, please consider upvoting. After all, every upvote is a small vote for the sanity of data scientists everywhere."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38.652008,
   "end_time": "2025-03-18T08:03:24.464640",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-18T08:02:45.812632",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
